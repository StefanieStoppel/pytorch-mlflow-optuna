{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PyTorch: Using MLflow and Optuna for experiment tracking and hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import time\n",
    "\n",
    "import optuna\n",
    "import mlflow\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from mlflow import pytorch\n",
    "from pprint import pformat\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, dropout=0.0):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(dropout)\n",
    "        self.dropout2 = nn.Dropout2d(dropout)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train and validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(options, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_set_size = len(train_loader.dataset)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % options[\"log_interval\"] == 0:\n",
    "            # Log batch loss using mlflow\n",
    "            mlflow.log_metric(\"train_batch_nll_loss\", loss.item())\n",
    "            batch_size = len(data)\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * batch_size}/{train_set_size} \"\n",
    "                  f\"({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_set_size = len(test_loader.dataset)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= test_set_size\n",
    "    # Log average test set loss using mlflow\n",
    "    mlflow.log_metric(\"test_nll_loss\", test_loss)\n",
    "\n",
    "    print(f\"Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{test_set_size} \"\n",
    "          f\"({100. * correct / test_set_size:.0f}%)\\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artifact_path(active_run):\n",
    "    parsed_uri = urlparse(active_run.info.artifact_uri)\n",
    "    artifact_path = os.path.abspath(os.path.join(parsed_uri.netloc, parsed_uri.path))\n",
    "    return artifact_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Obtain hyperparameters for this trial\n",
    "def suggest_hyperparameters(trial):\n",
    "    # Obtain the learning rate on a logarithmic scale\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-1, log=True)\n",
    "    # Obtain the dropout ratio in a range from 0.0 to 0.9 with step size 0.1\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.9, step=0.1)\n",
    "    # Obtain the batch size (as power of 2)\n",
    "    batch_size = 2 ** trial.suggest_int(\"batch_size_power\", 5, 8, step=1)\n",
    "    # Obtain the optimizer to use by name\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer_name\", [\"Adam\", \"Adadelta\"])\n",
    "    \n",
    "    print(f\"Suggested hyperparameters: \\n{pformat(trial.params)}\")\n",
    "    # Log the obtained trial parameters using mlflow\n",
    "    mlflow.log_params(trial.params)\n",
    "    return lr, dropout, optimizer_name, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "def objective(trial, experiment, options=None):\n",
    "    # Start mlflow run\n",
    "    with mlflow.start_run(experiment_id=experiment.experiment_id):\n",
    "        print(f\"\\n**************************\")\n",
    "\n",
    "        active_run = mlflow.active_run()\n",
    "        print(f\"Starting run {active_run.info.run_id}\")\n",
    "\n",
    "        artifact_path = get_artifact_path(active_run)\n",
    "        print(f\"Artifact path for this run: {artifact_path}\")\n",
    "        \n",
    "        # Use mlflow to log params\n",
    "        mlflow.log_params(options)\n",
    "\n",
    "        # Use CUDA if GPU is available\n",
    "        use_cuda = options[\"use_cuda\"] and torch.cuda.is_available()\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        # Log mlflow device parameter\n",
    "        mlflow.log_param(\"device\", device)\n",
    "\n",
    "        # Get hyperparameter suggestions created by optuna\n",
    "        lr, dropout, optimizer_name, batch_size = suggest_hyperparameters(trial)\n",
    "\n",
    "        # Load the MNIST train and test datasets and save them to ./data\n",
    "        mnist_train = datasets.MNIST('./data', train=True, download=True, transform=transforms.Compose([\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                       ]))\n",
    "        train_loader = torch.utils.data.DataLoader(mnist_train,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True)\n",
    "        mnist_test = datasets.MNIST('./data', train=False, download=True, transform=transforms.Compose([\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                       ]))\n",
    "        test_loader = torch.utils.data.DataLoader(mnist_test,\n",
    "                                                  batch_size=1000,\n",
    "                                                  shuffle=True)\n",
    "        # Initialize network\n",
    "        model = Net(dropout=dropout).to(device)\n",
    "\n",
    "        # Pick an optimizer based on optuna's parameter suggestion\n",
    "        if optimizer_name == \"Adam\":\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        if optimizer_name == \"Adadelta\":\n",
    "            optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "        scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(0, options[\"epochs\"]):\n",
    "            train(options, model, device, train_loader, optimizer, epoch)\n",
    "            loss = test(model, device, test_loader)\n",
    "            scheduler.step()\n",
    "\n",
    "        # Save the model using mlflow\n",
    "        if options[\"save_model\"]:\n",
    "            pytorch.save_model(model, f\"{artifact_path}/mnist_model\")\n",
    "\n",
    "    # Return the test loss to be minimized by the network\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "def main(options=None):\n",
    "    # Create mlflow experiment if it doesn't exist already\n",
    "    experiment_name = options[\"experiment_name\"]\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    if experiment is None:\n",
    "        mlflow.create_experiment(experiment_name)\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    # Propagate logs to the root logger.\n",
    "    optuna.logging.set_verbosity(verbosity=optuna.logging.INFO)\n",
    "\n",
    "    # Create the optuna study which shares the experiment name\n",
    "    study = optuna.create_study(study_name=experiment_name, direction=\"minimize\")\n",
    "    study.optimize(lambda trial: objective(trial, experiment, options), n_trials=2)\n",
    "\n",
    "    # Filter optuna trials by state\n",
    "    pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "    complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "    print(\"\\n++++++++++++++++++++++++++++++++++\\n\")\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Trial number: \", trial.number)\n",
    "    print(\"  Loss (trial value): \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************\n",
      "Starting run 98ee2469c0a9442495da21a907e433fb\n",
      "Artifact path for this run: /home/steffi/dev/blog/pytorch-mlflow-optuna/mlruns/0/98ee2469c0a9442495da21a907e433fb/artifacts\n",
      "Suggested hyperparameters: \n",
      "{'batch_size_power': 7,\n",
      " 'dropout': 0.5,\n",
      " 'lr': 0.00019711211359145977,\n",
      " 'optimizer_name': 'Adam'}\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.323206\n",
      "Train Epoch: 0 [1280/60000 (2%)]\tLoss: 1.819211\n",
      "Train Epoch: 0 [2560/60000 (4%)]\tLoss: 1.289423\n",
      "Train Epoch: 0 [3840/60000 (6%)]\tLoss: 0.971882\n",
      "Train Epoch: 0 [5120/60000 (9%)]\tLoss: 0.739786\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.686343\n",
      "Train Epoch: 0 [7680/60000 (13%)]\tLoss: 0.489130\n",
      "Train Epoch: 0 [8960/60000 (15%)]\tLoss: 0.578423\n",
      "Train Epoch: 0 [10240/60000 (17%)]\tLoss: 0.486571\n",
      "Train Epoch: 0 [11520/60000 (19%)]\tLoss: 0.548882\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.478000\n",
      "Train Epoch: 0 [14080/60000 (23%)]\tLoss: 0.537154\n",
      "Train Epoch: 0 [15360/60000 (26%)]\tLoss: 0.394407\n",
      "Train Epoch: 0 [16640/60000 (28%)]\tLoss: 0.339259\n",
      "Train Epoch: 0 [17920/60000 (30%)]\tLoss: 0.450722\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.343905\n",
      "Train Epoch: 0 [20480/60000 (34%)]\tLoss: 0.365901\n",
      "Train Epoch: 0 [21760/60000 (36%)]\tLoss: 0.290588\n",
      "Train Epoch: 0 [23040/60000 (38%)]\tLoss: 0.370837\n",
      "Train Epoch: 0 [24320/60000 (41%)]\tLoss: 0.434014\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.283944\n",
      "Train Epoch: 0 [26880/60000 (45%)]\tLoss: 0.467993\n",
      "Train Epoch: 0 [28160/60000 (47%)]\tLoss: 0.299730\n",
      "Train Epoch: 0 [29440/60000 (49%)]\tLoss: 0.333874\n",
      "Train Epoch: 0 [30720/60000 (51%)]\tLoss: 0.314639\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.323423\n",
      "Train Epoch: 0 [33280/60000 (55%)]\tLoss: 0.293231\n",
      "Train Epoch: 0 [34560/60000 (58%)]\tLoss: 0.399398\n",
      "Train Epoch: 0 [35840/60000 (60%)]\tLoss: 0.400498\n",
      "Train Epoch: 0 [37120/60000 (62%)]\tLoss: 0.247068\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.421606\n",
      "Train Epoch: 0 [39680/60000 (66%)]\tLoss: 0.251996\n",
      "Train Epoch: 0 [40960/60000 (68%)]\tLoss: 0.377391\n",
      "Train Epoch: 0 [42240/60000 (70%)]\tLoss: 0.270924\n",
      "Train Epoch: 0 [43520/60000 (72%)]\tLoss: 0.287900\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.279479\n",
      "Train Epoch: 0 [46080/60000 (77%)]\tLoss: 0.251292\n",
      "Train Epoch: 0 [47360/60000 (79%)]\tLoss: 0.343639\n",
      "Train Epoch: 0 [48640/60000 (81%)]\tLoss: 0.197172\n",
      "Train Epoch: 0 [49920/60000 (83%)]\tLoss: 0.180165\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.229630\n",
      "Train Epoch: 0 [52480/60000 (87%)]\tLoss: 0.194704\n",
      "Train Epoch: 0 [53760/60000 (90%)]\tLoss: 0.294569\n",
      "Train Epoch: 0 [55040/60000 (92%)]\tLoss: 0.191797\n",
      "Train Epoch: 0 [56320/60000 (94%)]\tLoss: 0.302841\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.122216\n",
      "Train Epoch: 0 [58880/60000 (98%)]\tLoss: 0.235638\n",
      "Test set: Average loss: 0.1128, Accuracy: 9649/10000 (96%)\n",
      "\n",
      "\n",
      "**************************\n",
      "Starting run 81314c513a634e768a41a356c92a7cd6\n",
      "Artifact path for this run: /home/steffi/dev/blog/pytorch-mlflow-optuna/mlruns/0/81314c513a634e768a41a356c92a7cd6/artifacts\n",
      "Suggested hyperparameters: \n",
      "{'batch_size_power': 8,\n",
      " 'dropout': 0.7000000000000001,\n",
      " 'lr': 0.008041911553354405,\n",
      " 'optimizer_name': 'Adam'}\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.327921\n",
      "Train Epoch: 0 [2560/60000 (4%)]\tLoss: 1.726475\n",
      "Train Epoch: 0 [5120/60000 (9%)]\tLoss: 1.419155\n",
      "Train Epoch: 0 [7680/60000 (13%)]\tLoss: 1.271421\n",
      "Train Epoch: 0 [10240/60000 (17%)]\tLoss: 1.232424\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 1.155440\n",
      "Train Epoch: 0 [15360/60000 (26%)]\tLoss: 1.137997\n",
      "Train Epoch: 0 [17920/60000 (30%)]\tLoss: 1.106316\n",
      "Train Epoch: 0 [20480/60000 (34%)]\tLoss: 0.972645\n",
      "Train Epoch: 0 [23040/60000 (38%)]\tLoss: 1.030012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steffi/dev/blog/pytorch-mlflow-optuna/venv/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "OPTIONS = {\n",
    "    \"experiment_name\": \"pytorch-optuna-mlflow\",\n",
    "    \"epochs\": 1,\n",
    "    \"use_cuda\": False,\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": True\n",
    "}\n",
    "main(options=OPTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}